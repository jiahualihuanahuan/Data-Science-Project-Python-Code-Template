{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d46ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e75d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data preprocessing\n",
    "image_size = (224,224)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "class_mode = 'binary' # for multi-class classification problem, use: class_mode = 'category' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfb4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df=pd.read_csv('D:/Kaggle/Is a Block Structure Stable or Unstable/blocks-labels.csv',dtype=str)\n",
    "\n",
    "\n",
    "\n",
    "def append_ext(fn):\n",
    "    return fn+\".jpg\"\n",
    "\n",
    "train_df[\"id\"] = train_df[\"id\"].apply(append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfb875c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nfrom skimage import data, img_as_float, exposure, io\\n\\nfor img_path in train_df[\"id\"]:\\n    # Load images\\n    img = io.imread(f\"D:/Kaggle/Is a Block Structure Stable or Unstable/train/{img_path}\")\\n\\n    # Contrast stretching\\n    p2, p98 = np.percentile(img, (2, 98))\\n    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\\n    io.imsave(f\"D:/Kaggle/Is a Block Structure Stable or Unstable/contrast_stretching/{img_path}\", img_rescale)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change contract of each images using contrast_stretching method\n",
    "# https://github.com/sakares/histogram-equalization/blob/master/hist-equalize.ipynb\n",
    "'''import numpy as np\n",
    "from skimage import data, img_as_float, exposure, io\n",
    "\n",
    "for img_path in train_df[\"id\"]:\n",
    "    # Load images\n",
    "    img = io.imread(f\"D:/Kaggle/Is a Block Structure Stable or Unstable/train/{img_path}\")\n",
    "\n",
    "    # Contrast stretching\n",
    "    p2, p98 = np.percentile(img, (2, 98))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    io.imsave(f\"D:/Kaggle/Is a Block Structure Stable or Unstable/contrast_stretching/{img_path}\", img_rescale)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d89919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_directory = 'D:/Kaggle/Is a Block Structure Stable or Unstable/contrast_stretching/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654d0197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34355 validated image filenames belonging to 2 classes.\n",
      "Found 16921 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.33 # set validation split\n",
    "    ) \n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory = \"D:/Kaggle/Is a Block Structure Stable or Unstable/contrast_stretching/\",\n",
    "    x_col = \"id\",\n",
    "    y_col = \"stable\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode, # for multi-class classification problem, use 'category'\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory = \"D:/Kaggle/Is a Block Structure Stable or Unstable/contrast_stretching/\",\n",
    "    x_col = \"id\",\n",
    "    y_col = \"stable\",\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode, # for multi-class classification problem, use 'category'\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99188337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 25,821,249\n",
      "Trainable params: 25,768,129\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a model\n",
    "base_model = tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7a5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=tf.keras.metrics.BinaryAccuracy())\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"D:/Kaggle/Is a Block Structure Stable or Unstable/model/ResNet50_original_photo_stable.h5\", \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=False, \n",
    "                             mode='auto', \n",
    "                             save_freq='epoch')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                      min_delta=0.0001, \n",
    "                      patience=3, \n",
    "                      verbose=1,\n",
    "                      restore_best_weights=True,\n",
    "                      mode='auto')\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                            patience=1,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.1,\n",
    "                                            min_lr=0.0000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5062d6f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenny\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py:5016: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2147/2147 [==============================] - 205s 92ms/step - loss: 0.3303 - binary_accuracy: 0.8243 - val_loss: 0.1158 - val_binary_accuracy: 0.9538\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11577, saving model to D:/Kaggle/Is a Block Structure Stable or Unstable/model\\ResNet50_stable_or_not.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jenny\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "2147/2147 [==============================] - 197s 92ms/step - loss: 0.0828 - binary_accuracy: 0.9692 - val_loss: 0.0698 - val_binary_accuracy: 0.9707\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11577 to 0.06983, saving model to D:/Kaggle/Is a Block Structure Stable or Unstable/model\\ResNet50_stable_or_not.h5\n",
      "Epoch 3/1000\n",
      "2147/2147 [==============================] - 196s 91ms/step - loss: 0.0534 - binary_accuracy: 0.9814 - val_loss: 0.0518 - val_binary_accuracy: 0.9823\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06983 to 0.05185, saving model to D:/Kaggle/Is a Block Structure Stable or Unstable/model\\ResNet50_stable_or_not.h5\n",
      "Epoch 4/1000\n",
      "2147/2147 [==============================] - 196s 91ms/step - loss: 0.0346 - binary_accuracy: 0.9879 - val_loss: 0.0327 - val_binary_accuracy: 0.9877\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05185 to 0.03270, saving model to D:/Kaggle/Is a Block Structure Stable or Unstable/model\\ResNet50_stable_or_not.h5\n",
      "Epoch 5/1000\n",
      "2147/2147 [==============================] - 195s 91ms/step - loss: 0.0337 - binary_accuracy: 0.9895 - val_loss: 0.0396 - val_binary_accuracy: 0.9844\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03270\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 6/1000\n",
      "2147/2147 [==============================] - 195s 91ms/step - loss: 0.0112 - binary_accuracy: 0.9960 - val_loss: 0.0186 - val_binary_accuracy: 0.9933\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03270 to 0.01859, saving model to D:/Kaggle/Is a Block Structure Stable or Unstable/model\\ResNet50_stable_or_not.h5\n",
      "Epoch 7/1000\n",
      "2147/2147 [==============================] - 195s 91ms/step - loss: 0.0050 - binary_accuracy: 0.9983 - val_loss: 0.0200 - val_binary_accuracy: 0.9944\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01859\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 8/1000\n",
      "2147/2147 [==============================] - 195s 91ms/step - loss: 0.0024 - binary_accuracy: 0.9991 - val_loss: 0.0213 - val_binary_accuracy: 0.9947\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01859\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 9/1000\n",
      "2147/2147 [==============================] - 196s 92ms/step - loss: 0.0019 - binary_accuracy: 0.9993 - val_loss: 0.0216 - val_binary_accuracy: 0.9946\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01859\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit/train model\n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = nb_epochs,\n",
    "    callbacks=[checkpoint, early, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecf2b024",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17956\\694253533.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f74a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
